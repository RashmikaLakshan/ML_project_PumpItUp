{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PumpItUp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ExW4Hs8y3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7b790f-e416-44bf-9d67-b9a815bb921f"
      },
      "source": [
        " from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "# from sklearn.metrics import accuracy_score\n",
        "import datetime\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqOgQnTpYXgi"
      },
      "source": [
        "Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCEwCAWj9MLE"
      },
      "source": [
        "# Import data\n",
        "X_full = pd.read_csv('/content/drive/My Drive/PUMPITUP/TrainingSetValues.csv')\n",
        "X_test_full = pd.read_csv('/content/drive/My Drive/PUMPITUP/TestSetValues.csv')\n",
        "Y_full = pd.read_csv('/content/drive/My Drive/PUMPITUP/TrainingSetLabels.csv')\n",
        "submission_file = pd.read_csv(\"/content/drive/My Drive/PUMPITUP/Format.csv\")\n",
        "\n",
        "X_full.set_index('id',inplace=True)\n",
        "Y_full.set_index('id',inplace=True)\n",
        "X_test_full.set_index('id',inplace=True)\n",
        "X_test_full.reset_index(inplace=True)\n",
        "submission_file.set_index('id',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJcMQeloYQaC"
      },
      "source": [
        "Handle missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2IOqVb1kh3F"
      },
      "source": [
        "df_merged = pd.merge(Y_full, X_full, how = 'inner', left_index = True,right_index=True)\n",
        "df_merged.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeYVXbfIDpND"
      },
      "source": [
        "def date_parser(df):\n",
        "    date_recorder = list(map(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%d'),\n",
        "                             df['date_recorded'].values))\n",
        "    df['year_recorder'] = list(map(lambda x: int(x.strftime('%Y')), date_recorder))\n",
        "    df['weekday_recorder'] = list(map(lambda x: int(x.strftime('%w')), date_recorder))\n",
        "    df['yearly_week_recorder'] = list(map(lambda x: int(x.strftime('%W')), date_recorder))\n",
        "    df['month_recorder'] = list(map(lambda x: int(x.strftime('%m')), date_recorder))\n",
        "    df['age'] = df['year_recorder'].values - df['construction_year'].values\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPeI5q0rtQ72"
      },
      "source": [
        "def createDecadeColumn(df):\n",
        "  df['construction_year'].replace(to_replace = 0, value = 2000, inplace=True)\n",
        "  df['decade'] = df['construction_year']\n",
        "\n",
        "  # dividing the column decades\n",
        "  df['decade'].replace(to_replace = (1960,1961,1962,1963,1964,1965,1966,1967,1968,1969),\n",
        "                          value ='60s' , inplace=True)\n",
        "  df['decade'].replace(to_replace = (1970,1971,1972,1973,1974,1975,1976,1977,1978,1979),\n",
        "                          value ='70s' , inplace=True)\n",
        "  df['decade'].replace(to_replace = (1980,1981,1982,1983,1984,1985,1986,1987,1988,1989),\n",
        "                          value ='80s' , inplace=True)\n",
        "  df['decade'].replace(to_replace = (1990,1991,1992,1993,1994,1995,1996,1997,1998,1999),\n",
        "                          value ='90s' , inplace=True)\n",
        "  df['decade'].replace(to_replace = (2000,2001,2002,2003,2004,2005,2006,2007,2008,2009),\n",
        "                          value ='00s' , inplace=True)\n",
        "  df['decade'].replace(to_replace = (2010,2011,2012,2013),\n",
        "                          value ='10s' , inplace=True)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un2gidbevjqw"
      },
      "source": [
        "def reOrderInstallerColumn(df):\n",
        "  df['installer'].fillna(value='Unknown',inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = '0', value ='Unknown' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('District Water Department', 'District water depar','Distric Water Department'),\n",
        "                          value ='District water department' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('FinW','Fini water','FINI WATER'), value ='Fini Water' , inplace=True)\n",
        "  df['installer'].replace(to_replace = 'JAICA', value ='Jaica' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('COUN', 'District COUNCIL', 'DISTRICT COUNCIL','District Counci', \n",
        "                                        'District Council','Council','Counc','District  Council','Distri'),\n",
        "                                      value ='District council' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('RC CHURCH', 'RC Churc', 'RC','RC Ch','RC C', 'RC CH','RC church', \n",
        "                                        'RC CATHORIC',) , value ='RC Church' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('Central Government','Tanzania Government',\n",
        "                                        'central government','Cental Government', 'Cebtral Government', \n",
        "                                        'Tanzanian Government','Tanzania government', 'Centra Government' ,\n",
        "                                        'CENTRAL GOVERNMENT', 'TANZANIAN GOVERNMENT','Central govt', 'Centr', \n",
        "                                        'Centra govt') , value ='Central government' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('World vision', 'World Division','World Vision'),\n",
        "                                          value ='world vision' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('Unisef','UNICEF'),value ='Unicef' , inplace=True)\n",
        "  df['installer'].replace(to_replace = 'DANID', value ='DANIDA' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('villigers', 'villager', 'Villagers', 'Villa', 'Village', 'Villi', \n",
        "                                        'Village Council','Village Counil', 'Villages', 'Vill', 'Village community', \n",
        "                                        'Villaers', 'Village Community', 'Villag','Villege Council', 'Village council',\n",
        "                                        'Village  Council','Villagerd', 'Villager', 'Village Technician',\n",
        "                                        'Village Office','Village community members'),\n",
        "                                          value ='villagers' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace =('Commu','Communit','commu','COMMU', 'COMMUNITY') ,\n",
        "                                          value ='Community' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('GOVERNMENT', 'GOVER', 'GOVERNME', 'GOVERM','GOVERN','Gover','Gove',\n",
        "                                        'Governme','Governmen' ) ,value ='Government' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = 'Hesawa' ,value ='HESAWA' , inplace=True)\n",
        "\n",
        "  df['installer'].replace(to_replace = ('Colonial Government') , value ='Colonial government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Government of Misri') , value ='Misri Government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Italy government') , value ='Italian government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('British colonial government') , value ='British government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Concern /government') , value ='Concern/Government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Village Government') , value ='Village government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Government and Community') , value ='Government /Community' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Cetral government /RC') , value ='RC church/Central Gover' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('Government /TCRS','Government/TCRS') , value ='TCRS /Government' , inplace=True)\n",
        "  df['installer'].replace(to_replace = ('ADRA /Government') , value ='ADRA/Government' , inplace=True)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWIdpfr_wTMP"
      },
      "source": [
        "def dropnAddMissingValuesforSpecialColums(df):\n",
        "  df['funder'].fillna(value='Unknown',inplace=True)\n",
        "  df['public_meeting'].fillna(value=True,inplace=True)\n",
        "  df['permit'].fillna(value=True, inplace=True)\n",
        "\n",
        "  df['funder'].replace(to_replace = '0', value ='Unknown' , inplace=True)\n",
        "  df['longitude'].replace(to_replace = 0 , value =35.15, inplace=True)\n",
        "  df['population'].replace(to_replace = 0 , value =281, inplace=True)\n",
        "\n",
        "  df.drop(columns=['subvillage', 'num_private', 'date_recorded', 'amount_tsh', 'wpt_name','scheme_name','id','region_code', \n",
        "                  'management_group','scheme_management','quantity_group','source_class','source_type','quality_group',\n",
        "                'payment_type','extraction_type_class','extraction_type', 'waterpoint_type_group', 'recorded_by'],inplace=True )\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MJbxQikBD44"
      },
      "source": [
        "df = dropnAddMissingValuesforSpecialColums( reOrderInstallerColumn( createDecadeColumn( date_parser(df_merged.copy()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMwY1dJFktbn"
      },
      "source": [
        "df.dropna(axis=0, subset=[\"status_group\"], inplace=True)\n",
        "Y = pd.DataFrame(df.status_group)        \n",
        "df.drop([\"status_group\"], axis=1, inplace=True)\n",
        "X = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNKDPrD1BIeq"
      },
      "source": [
        "X_testNew = dropnAddMissingValuesforSpecialColums( reOrderInstallerColumn( createDecadeColumn( date_parser( X_test_full.copy()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly2qeh_uWapr"
      },
      "source": [
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "\n",
        "def encoding(df):\n",
        "\n",
        "  # Preprocessing for numerical data\n",
        "  numerical_transformer = SimpleImputer(strategy='constant')\n",
        "  df[numerical_cols] = numerical_transformer.fit_transform(df[numerical_cols])\n",
        "\n",
        "  # Preprocessing for categorical data\n",
        "  categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
        "  df[categorical_cols] = categorical_transformer.fit_transform(df[categorical_cols])\n",
        "\n",
        "  for i in categorical_cols:\n",
        "    df[i] = LabelEncoder().fit_transform(df[i].values)\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n",
        "# # Preprocessing for numerical data\n",
        "# numerical_transformer = SimpleImputer(strategy='constant')\n",
        "\n",
        "# # Preprocessing for categorical data\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "\n",
        "\n",
        "# # Bundle preprocessing for numerical and categorical data\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('num', numerical_transformer, numerical_cols),\n",
        "#         ('cat', categorical_transformer, categorical_cols)\n",
        "#     ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4bKml2ROsc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d584132c-6fd3-440a-e3e2-dde514930506"
      },
      "source": [
        "# Change labels to ints in order to use as y vector\n",
        "label_encoder = LabelEncoder()\n",
        "Y[\"status_group\"] = label_encoder.fit_transform(Y.status_group.values)\n",
        "Y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   status_group\n",
              "0             0\n",
              "1             0\n",
              "2             0\n",
              "3             2\n",
              "4             0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhbT7dDuZnBJ"
      },
      "source": [
        "Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNJ67Y5cm9Jp"
      },
      "source": [
        "X_train = encoding(X[my_cols].copy())\n",
        "Y_train = Y.copy()\n",
        "X_test = encoding(X_testNew[my_cols].copy())\n",
        "\n",
        "# X_train = X[my_cols].copy()\n",
        "# Y_train = Y.copy()\n",
        "# X_test = X_testNew[my_cols].copy()\n",
        "\n",
        "# X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpoWi3iX2MAk"
      },
      "source": [
        "**model train testing for finding better accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNgKxK6zhJ3t"
      },
      "source": [
        "def modelTraining(n_est, depth):\n",
        "  model = XGBClassifier(n_estimators=n_est, max_depth=depth)\n",
        "\n",
        "  model.fit(X_train, Y_train.values.ravel())\n",
        "\n",
        "  kfold = KFold(n_splits=10, shuffle=True)\n",
        "  kf_cv_scores = cross_val_score(model, X_train, Y_train.values.ravel(), cv=kfold )\n",
        "  return kf_cv_scores.mean()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYNp_A4KjlrM"
      },
      "source": [
        "cols = ['n_estimates', 'depth', 'accuracy']\n",
        "trainingResults = pd.DataFrame(columns = cols)\n",
        "\n",
        "for n_est in range(1, 11):\n",
        "  for depth in range(3, 6):\n",
        "    acc = modelTraining(n_est*50, depth)\n",
        "    print(n_est*50, depth, acc)\n",
        "    data = [{'n_estimates': n_est*50,'depth': depth,'accuracy': acc}]\n",
        "    trainingResults = trainingResults.append(data,ignore_index=True,sort=False)\n",
        "\n",
        "trainingResults.to_csv(path_or_buf=\"/content/drive/My Drive/PUMPITUP/accuracyStack.csv\")\n",
        "trainingResults.loc(trainingResults['accuracy'].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF5e7j8zvZIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "7644ceca-e099-4068-c9aa-7f9d3e113618"
      },
      "source": [
        "\n",
        "trainingResults.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-49943ce1c939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainingResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainingResults' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fu_s_5M2a0F"
      },
      "source": [
        "**testing done**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCE9HIOsC_u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29c9114-f9d1-494b-b5a1-209ccdfa56e0"
      },
      "source": [
        "model = XGBClassifier(n_estimators=500, max_depth=5)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
            "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1oPSy61DC46"
      },
      "source": [
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "# clf = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxhSlLM-cQTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b03daf4-69ad-40b6-924e-d2aad467ecff"
      },
      "source": [
        "# clf.fit(X_train, Y_train)\n",
        "# clf.fit(X_train, Y_train.values.ravel())\n",
        "model.fit(X_train, Y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
              "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lws6rIfcP4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60549066-8dbf-427a-95ef-c1ee6c7a906a"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "# kf_cv_scores = cross_val_score(clf, X_train, Y_train.values.ravel(), cv=kfold )\n",
        "kf_cv_scores = cross_val_score(model, X_train, Y_train.values.ravel(), cv=kfold )\n",
        "print(\"K-fold CV average score: %.4f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold CV average score: 0.8011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P5Pv1fmlxzq"
      },
      "source": [
        "preds = model.predict(X_test)\n",
        "# preds = clf.predict(X_test)\n",
        "submission = label_encoder.inverse_transform(preds)\n",
        "submission_file['status_group'] = submission\n",
        "submission_file.to_csv(path_or_buf=\"/content/drive/My Drive/PUMPITUP/Submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}